{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Structures Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Record import *\n",
    "import os\n",
    "\n",
    "\n",
    "class Block:\n",
    "    def __init__(self, disk_name):\n",
    "        \"\"\" Constructor \"\"\"\n",
    "        # open disk file\n",
    "        if (os.path.isfile('./' + disk_name)):\n",
    "            self.disk = open(disk_name, \"r+\")\n",
    "        else:\n",
    "            self.disk = open(disk_name, \"w+\")\n",
    "        # set size of block\n",
    "        self.max_size = 8\n",
    "        # set number of operations (read/write)\n",
    "        self.n_op = 0\n",
    "        # set list of records\n",
    "        self.records = []\n",
    "        # record size\n",
    "        self.record_size = 138\n",
    "        self.pos = 0\n",
    "\n",
    "    def __del__(self):\n",
    "        \"\"\" Destructor \"\"\"\n",
    "        # persist last records to disk\n",
    "        self.persist(self.disk.tell())\n",
    "        # close disk file\n",
    "        self.disk.close()\n",
    "\n",
    "    def persist(self, pos):\n",
    "        \"\"\" Persists current block's records to the disk file \"\"\"\n",
    "        # add 1 to number of operations\n",
    "        self.n_op += 1\n",
    "        # position the pointer at the writing location\n",
    "        self.disk.seek(pos)\n",
    "        # persist each block record to disk file\n",
    "        for rec in self.records:\n",
    "            self.disk.write(str(rec))\n",
    "        self.disk.flush()\n",
    "        # reset list of records\n",
    "        self.records = []\n",
    "\n",
    "    def write(self, pos, rec):\n",
    "        \"\"\" Write record rec in position pos of the disk file \"\"\"\n",
    "        if (len(self.records) >= self.max_size):\n",
    "            self.persist(pos)\n",
    "        self.records += [rec]\n",
    "        self.pos = pos\n",
    "\n",
    "    def read(self, pos):\n",
    "        \"\"\" Add records of pos position in disk file to this \"\"\"\n",
    "        self.n_op += 1\n",
    "        self.records = []\n",
    "        self.disk.seek(pos)\n",
    "        while (len(self.records) < self.max_size):\n",
    "            self.records += [self.disk.read(self.record_size)]\n",
    "\n",
    "\n",
    "# r = Record(\"11111111111;54.037.661-5;estermoro@gmail.com;06/01/1952;Feminino;Yuri Matheus Antonia;5942.00\")\n",
    "# b = Block(\"out.txt\")\n",
    "# b.write(500, str(r))\n",
    "# b.persist(500)\n",
    "# b.read(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Record:\n",
    "    def __init__(self, string):\n",
    "        \"\"\" Split argument (record) by ; character and set member variables \"\"\"\n",
    "        # set splited record\n",
    "        field = string.split(';')\n",
    "        # set cpf\n",
    "        self.cpf = field[0]\n",
    "        # set rg\n",
    "        self.rg = field[1]\n",
    "        # set email\n",
    "        self.email = field[2] + '\\0' * \\\n",
    "            (40 - len(field[2])) if len(field[2]) < 40 else field[2][:40]\n",
    "        # set data de nascimento\n",
    "        self.nasc = field[3]\n",
    "        # set sexo\n",
    "        self.sexo = field[4] + '\\0' * \\\n",
    "            (9 - len(field[4])) if len(field[4]) < 9 else field[4][:9]\n",
    "        # set nome\n",
    "        self.nome = field[5] + '\\0'*(40 - len(field[5])\n",
    "                                     ) if len(field[5]) < 40 else field[5][:40]\n",
    "        # set salario\n",
    "        self.salario = field[6] + '\\0' * \\\n",
    "            (10 - len(field[6])) if len(field[6]) < 10 else field[6][:10]\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\" Return all member variables concatenated \"\"\"\n",
    "        return self.cpf+\";\"+self.rg+\";\"+self.email+\";\"+self.nasc+\";\"+self.sexo+\";\"+self.nome+\";\"+self.salario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B-Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As seen in https://gist.github.com/natekupp/1763661\n",
    "class BTreeNode(object):\n",
    "    \"\"\"A B-Tree Node.\n",
    "    \n",
    "    attributes\n",
    "    =====================\n",
    "    leaf : boolean, determines whether this node is a leaf.\n",
    "    keys : list, a list of keys internal to this node\n",
    "    c : list, a list of children of this node\n",
    "    \"\"\"\n",
    "    def __init__(self, leaf=False):\n",
    "        self.leaf = leaf\n",
    "        self.keys = []\n",
    "        self.c    = []\n",
    "        self.pos=0 #added node's content\n",
    "        \n",
    "    def __str__(self):\n",
    "        if self.leaf:\n",
    "            return \"Leaf BTreeNode with {0} keys\\n\\tK:{1}\\n\\tC:{2}\\n\".format(len(self.keys), self.keys, self.c)\n",
    "        else:\n",
    "            return \"Internal BTreeNode with {0} keys, {1} children\\n\\tK:{2}\\n\\n\".format(len(self.keys), len(self.c), self.keys, self.c)\n",
    "\n",
    "\n",
    "class BTree(object):\n",
    "    def __init__(self, t):\n",
    "        self.root = BTreeNode(leaf=True)\n",
    "        self.t    = t\n",
    "    \n",
    "    def search(self, k, x=None):\n",
    "        \"\"\"Search the B-Tree for the key k.\n",
    "        \n",
    "        args\n",
    "        =====================\n",
    "        k : Key to search for\n",
    "        x : (optional) Node at which to begin search. Can be None, in which case the entire tree is searched.\n",
    "        \n",
    "        \"\"\"\n",
    "        if isinstance(x, BTreeNode):\n",
    "            i = 0\n",
    "            while i < len(x.keys) and k > x.keys[i]:    # look for index of k\n",
    "                i += 1\n",
    "            if i < len(x.keys) and k == x.keys[i]:       # found exact match\n",
    "                return (x, i)\n",
    "            elif x.leaf:                                # no match in keys, and is leaf ==> no match exists\n",
    "                return None\n",
    "            else:                                       # search children\n",
    "                return self.search(k, x.c[i])\n",
    "        else:                                           # no node provided, search root of tree\n",
    "            return self.search(k, self.root)\n",
    "        \n",
    "    def insert(self, k):\n",
    "        r = self.root\n",
    "        if len(r.keys) == (2*self.t) - 1:     # keys are full, so we must split\n",
    "            s         = BTreeNode()\n",
    "            self.root = s\n",
    "            s.c.insert(0, r)                  # former root is now 0th child of new root s\n",
    "            self._split_child(s, 0)            \n",
    "            self._insert_nonfull(s, k)\n",
    "        else:\n",
    "            self._insert_nonfull(r, k)\n",
    "    \n",
    "    def _insert_nonfull(self, x, k):\n",
    "        i = len(x.keys) - 1\n",
    "        if x.leaf:\n",
    "            # insert a key\n",
    "            x.keys.append(0)\n",
    "            while i >= 0 and k < x.keys[i]:\n",
    "                x.keys[i+1] = x.keys[i]\n",
    "                i -= 1\n",
    "            x.keys[i+1] = k\n",
    "        else:\n",
    "            # insert a child\n",
    "            while i >= 0 and k < x.keys[i]:\n",
    "                i -= 1\n",
    "            i += 1\n",
    "            if len(x.c[i].keys) == (2*self.t) - 1:\n",
    "                self._split_child(x, i)\n",
    "                if k > x.keys[i]:\n",
    "                    i += 1\n",
    "            self._insert_nonfull(x.c[i], k)\n",
    "        \n",
    "    def _split_child(self, x, i):\n",
    "        t = self.t\n",
    "        y = x.c[i]\n",
    "        z = BTreeNode(leaf=y.leaf)\n",
    "        \n",
    "        # slide all children of x to the right and insert z at i+1.\n",
    "        x.c.insert(i+1, z)\n",
    "        x.keys.insert(i, y.keys[t-1])\n",
    "        \n",
    "        # keys of z are t to 2t - 1,\n",
    "        # y is then 0 to t-2\n",
    "        z.keys = y.keys[t:(2*t - 1)]\n",
    "        y.keys = y.keys[0:(t-1)]\n",
    "        \n",
    "        # children of z are t to 2t els of y.c\n",
    "        if not y.leaf:\n",
    "            z.c = y.c[t:(2*t)]\n",
    "            y.c = y.c[0:(t-1)]    \n",
    "        \n",
    "    def __str__(self):\n",
    "        r = self.root\n",
    "        return r.__str__() + '\\n'.join([child.__str__() for child in r.c])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bplustree import BPlusTree, StrSerializer #pip install btreeplus\n",
    "#see https://github.com/NicolasLM/bplustree\n",
    "from os import getcwd\n",
    "from sys import byteorder\n",
    "\n",
    "\n",
    "class Heap:\n",
    "    def __init__(self, disk_name=\"Heap.cbd\", indexBy=[], indexBTree=True, indexBPlusTree=False):\n",
    "        maxDegreeBTree = 10\n",
    "        self.r_block = Block(disk_name)\n",
    "        self.w_block = Block(disk_name)\n",
    "        self.indexes = {}\n",
    "        self.indexBTree = indexBTree\n",
    "        self.indexBPlusTree = indexBPlusTree\n",
    "        for i in indexBy:\n",
    "            if indexBPlusTree:\n",
    "                self.indexes.update({i:BPlusTree(getcwd()+\"\\\\\"+i+\".index\",serializer=StrSerializer(),key_size=128)})\n",
    "            else:\n",
    "                if indexBTree:\n",
    "                    self.indexes.update({i:BTree(maxDegreeBTree)})\n",
    "                else:\n",
    "                    self.indexes.update({i:{}})\n",
    "\n",
    "    def __del__(self):\n",
    "        if self.indexBPlusTree:\n",
    "            for i in indexBy:\n",
    "                self.indexes[i].close()\n",
    "\n",
    "    def insert(self, string):\n",
    "        rec = Record(string)\n",
    "        for i in self.indexes:\n",
    "            if self.indexBPlusTree:\n",
    "                self.indexes[i].insert(getattr(rec,i),self.w_block.disk.tell().to_bytes(4,byteorder),True) #True for replacing node, if already existant\n",
    "            else:\n",
    "                if self.indexBTree:\n",
    "                    self.indexes[i].insert(getattr(rec,i))\n",
    "                    self.indexes[i].search(getattr(rec,i))[0].pos=self.w_block.disk.tell()\n",
    "                else:\n",
    "                    self.indexes[i].update({getattr(rec,i):self.w_block.disk.tell()})\n",
    "        self.w_block.write(self.w_block.disk.tell(), rec)\n",
    "\n",
    "    def join(self, other_heap, field, other_field=\"\"):\n",
    "        if not other_field:\n",
    "            other_field=field\n",
    "        pos, other_pos = 0, 0\n",
    "        self.r_block.read(pos)\n",
    "        while(self.r_block.records[0]):\n",
    "            for i in self.r_block.records:\n",
    "                if not i:\n",
    "                    break\n",
    "                if other_field in other_heap.indexes:  # if field is indexed\n",
    "                    if other_heap.indexBPlusTree:\n",
    "                        other_heap.r_block.read(int.from_bytes(other_heap.indexes[other_field].get(getattr(Record(i),field),byteorder)))\n",
    "                    else:\n",
    "                        if other_heap.indexBTree:\n",
    "                            other_heap.r_block.read(other_heap.indexes[other_field].search(getattr(Record(i),field))[0].pos)\n",
    "                        else:\n",
    "                            other_heap.r_block.read(other_heap.indexes[other_field][getattr(Record(i), field)]*other_heap.r_block.record_size)\n",
    "                    for j in other_heap.r_block.records:\n",
    "                        if not j:\n",
    "                            break\n",
    "                        if getattr(Record(i), field) == getattr(Record(j), other_field):\n",
    "                            print(i+\"\\n\"+j+\"\\n\")\n",
    "                else:  # if field is NOT indexed\n",
    "                    other_pos = 0\n",
    "                    other_heap.r_block.read(other_pos)\n",
    "                    while(other_heap.r_block.records[0]):\n",
    "                        for j in other_heap.r_block.records:\n",
    "                            if not j:\n",
    "                                break\n",
    "                            if getattr(Record(i), field) == getattr(Record(j), other_field):\n",
    "                                print(i+\"\\n\"+j+\"\\n\")\n",
    "                        other_pos += other_heap.r_block.max_size*other_heap.r_block.record_size\n",
    "                        other_heap.r_block.read(other_pos)\n",
    "            pos += self.r_block.max_size*self.r_block.record_size\n",
    "            self.r_block.read(pos)\n",
    "\n",
    "\n",
    "#a=Heap(\"teste1.cbd\",indexBy=[\"nome\"])\n",
    "#a.insert(\"11111111111;54.037.661-5;estermoro@gmail.com;06/01/1952;Feminino;Yuri Matheus Antonia;5942.00\")\n",
    "#a.insert(\"33333333333;54.037.661-5;estermoro@gmail.com;06/01/1952;Feminino;Yuri Matheus Antonia;5942.00\")\n",
    "#b=Heap(\"teste2.cbd\",indexBy=[\"nome\"])\n",
    "#b.insert(\"22222222222;54.037.661-5;estermoro@gmail.com;06/01/1952;Feminino;Yuri Matheus Antonia;5942.00\")\n",
    "\n",
    "#a.w_block.persist(0) #debug-only\n",
    "#b.w_block.persist(0) #debug-only\n",
    "\n",
    "#a.join(b, \"nome\")\n",
    "\n",
    "#del a, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sorted:\n",
    "    def __init__(self, disk_name=\"Sorted.cbd\", indexBy=[]):\n",
    "        self.disk_name = disk_name\n",
    "        self.r_block = Block(disk_name)\n",
    "        self.w_block = Block(disk_name)\n",
    "        self.indexes = {}\n",
    "        for i in indexBy:\n",
    "            self.indexes.update({i: open(i+\"_\"+disk_name, \"w+\")})\n",
    "\n",
    "    def __del__(self):\n",
    "        for i in self.indexes:\n",
    "            self.indexes[i].close()\n",
    "\n",
    "    def insert(self, string):\n",
    "        rec = Record(string)\n",
    "        self.w_block.write(self.w_block.disk.tell(), rec)\n",
    "        self.w_block.persist(self.w_block.disk.tell())\n",
    "        allRecords = []\n",
    "        pos = 0\n",
    "        self.r_block.read(pos)\n",
    "        while self.r_block.records[0]:\n",
    "            allRecords += self.r_block.records\n",
    "            pos += self.r_block.max_size*self.r_block.record_size\n",
    "            self.r_block.read(pos)\n",
    "        allRecords.sort()\n",
    "        sortedFile = open(self.disk_name, \"w\")\n",
    "        sortedFile.write(\"\".join(allRecords))\n",
    "        sortedFile.flush()\n",
    "        # + indexing implementation\n",
    "\n",
    "    def join(self, other_sorted, field, other_field=\"\"):\n",
    "        if not other_field:\n",
    "            other_field=field\n",
    "        pos, other_pos, pos_inside_block, other_pos_inside_block = 0, 0, 0, 0 #*_inside_block marks a record inside a block\n",
    "        self.r_block.read(pos)\n",
    "        while(self.r_block.records[0]):\n",
    "            other_sorted.r_block.read(other_pos)\n",
    "            while(other_sorted.r_block.records[0]):\n",
    "                if not self.r_block.records[pos_inside_block]:\n",
    "                    pos_inside_block=0\n",
    "                    pos+=self.r_block.max_size*self.r_block.record_size\n",
    "                    self.r_block.read(pos)\n",
    "                    break\n",
    "                if not other_sorted.r_block.records[other_pos_inside_block]:\n",
    "                    other_pos_inside_block=0\n",
    "                    other_pos+=other_sorted.r_block.max_size*other_sorted.r_block.record_size\n",
    "                    other_sorted.r_block.read(pos)\n",
    "                    break\n",
    "                if(getattr(Record(self.r_block.records[pos_inside_block]),field)==getattr(Record(other_sorted.r_block.records[other_pos_inside_block]),other_field)):\n",
    "                    print(self.r_block.records[pos_inside_block]+\"\\n\"+other_sorted.r_block.records[other_pos_inside_block]+\"\\n\")\n",
    "                    pos_inside_block+=1 #pair found, moves left table's pointer\n",
    "                else:\n",
    "                    if(getattr(Record(self.r_block.records[pos_inside_block]),field)<getattr(Record(other_sorted.r_block.records[other_pos_inside_block]),other_field)):\n",
    "                          pos_inside_block+=1 #moves left table's pointer\n",
    "                    else:\n",
    "                          other_pos_inside_block+=1 #moves right table's pointer\n",
    "                if(pos_inside_block>=self.r_block.max_size): #loads left table's next block\n",
    "                    pos_inside_block=0\n",
    "                    pos+=self.r_block.max_size*self.r_block.record_size\n",
    "                    self.r_block.read(pos)\n",
    "                if(other_pos_inside_block>=other_sorted.r_block.max_size): #loads right table's next block\n",
    "                    other_pos_inside_block=0\n",
    "                    other_pos+=other_sorted.r_block.max_size*other_sorted.r_block.record_size\n",
    "                    other_sorted.r_block.read(other_pos)\n",
    "                \n",
    "\n",
    "# a = Sorted()\n",
    "# a.insert(\"11111111111;54.037.661-5;estermoro@gmail.com;06/01/1952;Feminino;Yuri Matheus Antonia;5942.00\")\n",
    "# a.insert(\"33331111111;54.037.661-5;estermoro@gmail.com;06/01/1952;Feminino;Yuri Matheus Antonia;5942.00\")\n",
    "# a.insert(\"22222222222;54.037.661-5;estermoro@gmail.com;06/01/1952;Feminino;Yuri Matheus Antonia;5942.00\")\n",
    "\n",
    "#a=Sorted(\"teste1.cbd\")\n",
    "#a.insert(\"11111111111;54.037.661-5;estermoro@gmail.com;06/01/1952;Feminino;Yuri Matheus Antonia;5942.00\")\n",
    "#a.insert(\"33333333333;54.037.661-5;estermoro@gmail.com;06/01/1952;Feminino;Yuri Matheus Antonia;5942.00\")\n",
    "#b=Sorted(\"teste2.cbd\")\n",
    "#b.insert(\"22222222222;54.037.661-5;estermoro@gmail.com;06/01/1952;Feminino;Yuri Matheus Antonia;5942.00\")\n",
    "\n",
    "#a.join(b, \"nome\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Record import *\n",
    "# from Block import *\n",
    "# from BTree import *\n",
    "from bplustree import BPlusTree, StrSerializer #pip install btreeplus\n",
    "#see https://github.com/NicolasLM/bplustree\n",
    "from os import getcwd\n",
    "from sys import byteorder\n",
    "\n",
    "class Hash:\n",
    "    def __init__(self, disk_name=\"Hash.cbd\", indexBy=[], indexBTree=True, indexBPlusTree=False):\n",
    "        maxDegreeBTree = 10\n",
    "        self.r_block = Block(disk_name)\n",
    "        self.w_block = Block(disk_name)\n",
    "        self.indexes={}\n",
    "        self.indexBTree = indexBTree\n",
    "        self.indexBPlusTree = indexBPlusTree\n",
    "        self.hashedPositions = []\n",
    "        for i in indexBy:\n",
    "            if indexBPlusTree:\n",
    "                self.indexes.update({i:BPlusTree(getcwd()+\"\\\\\"+i+\".index\",serializer=StrSerializer(),key_size=128)})\n",
    "            else:\n",
    "                if indexBTree:\n",
    "                    self.indexes.update({i:BTree(maxDegreeBTree)})\n",
    "                else:\n",
    "                    self.indexes.update({i:{}})\n",
    "\n",
    "    def __del__(self):\n",
    "        if self.indexBPlusTree:\n",
    "            for i in indexBy:\n",
    "                self.indexes[i].close()\n",
    "\n",
    "    def insert(self, string):\n",
    "        rec = Record(string)\n",
    "        self.w_block.write(abs(hash(rec.cpf)//10**6)*self.w_block.max_size*self.w_block.record_size, rec)\n",
    "        self.w_block.persist(abs(hash(rec.cpf)//10**6)*self.w_block.max_size*self.w_block.record_size)\n",
    "        self.hashedPositions += [abs(hash(rec.cpf)//10**6)*self.w_block.max_size*self.w_block.record_size]\n",
    "        for i in self.indexes:\n",
    "            if self.indexBPlusTree:\n",
    "                self.indexes[i].insert(getattr(rec,i),abs(hash(rec.cpf)//10**6)*self.w_block.max_size*self.w_block.record_size.to_bytes(4,byteorder),True) #True for replacing node, if already existant\n",
    "            else:\n",
    "                if self.indexBTree:\n",
    "                    self.indexes[i].insert(getattr(rec,i))\n",
    "                    self.indexes[i].search(getattr(rec,i))[0].pos=abs(hash(rec.cpf)//10**6)*self.w_block.max_size*self.w_block.record_size\n",
    "                else:\n",
    "                    self.indexes[i].update({getattr(rec,i):abs(hash(rec.cpf)//10**6)*self.w_block.max_size*self.w_block.record_size})\n",
    "\n",
    "    def join(self,other_hash,field,other_field=\"\"):\n",
    "        if not other_field:\n",
    "            other_field=field\n",
    "        for pos in self.hashedPositions:\n",
    "            self.r_block.read(pos)\n",
    "            for i in self.r_block.records:\n",
    "                if i=='\\x00'*self.r_block.record_size or not i:\n",
    "                    break\n",
    "                if field==\"cpf\": #if field is primary key cpf\n",
    "                    other_hash.r_block.read(abs(hash(Record(i).cpf)//10**6)*self.w_block.max_size*self.w_block.record_size)\n",
    "                    if other_hash.r_block.records[0]!='\\x00'*self.r_block.record_size:\n",
    "                        print(i+\"\\n\"+str(other_hash.r_block.records[0])+\"\\n\")\n",
    "                else:\n",
    "                    if other_field in other_hash.indexes: #if field is indexed\n",
    "                        if other_hash.indexBPlusTree:\n",
    "                            other_hash.r_block.read(int.from_bytes(other_hash.indexes[other_field].get(getattr(Record(i),field),byteorder)))\n",
    "                        else:\n",
    "                            if other_hash.indexBTree:\n",
    "                                other_hash.r_block.read(other_hash.indexes[other_field].search(getattr(Record(i),field))[0].pos)\n",
    "                            else:\n",
    "                                other_hash.r_block.read(other_hash.indexes[other_field][getattr(Record(i),field)])\n",
    "                        for j in other_hash.r_block.records:\n",
    "                            if not j:\n",
    "                                break\n",
    "                            if getattr(Record(i),field)==getattr(Record(j),other_field):\n",
    "                                print(i+\"\\n\"+j+\"\\n\")\n",
    "                    else:\n",
    "                        other_pos = 0\n",
    "                        other_hash.r_block.read(other_pos)\n",
    "                        while(other_hash.r_block.records[0]):\n",
    "                            for j in other_hash.r_block.records:\n",
    "                                if j=='\\x00'*other_hash.r_block.record_size or not j:\n",
    "                                    break\n",
    "                                if getattr(Record(i), field) == getattr(Record(j), other_field):\n",
    "                                    print(i+\"\\n\"+j+\"\\n\")\n",
    "                            other_pos += other_hash.r_block.max_size*other_hash.r_block.record_size\n",
    "                            other_hash.r_block.read(other_pos)\n",
    "\n",
    "#a=Hash(\"teste1.cbd\",indexBy=[\"nome\"])\n",
    "#a.insert(\"11111111111;54.037.661-5;estermoro@gmail.com;06/01/1952;Feminino;Yuri Matheus Antonia;5942.00\")\n",
    "#b=Hash(\"teste2.cbd\",indexBy=[\"nome\"])\n",
    "#b.insert(\"11111111111;54.037.661-5;estermoro@gmail.com;06/01/1952;Feminino;Yuri Matheus Antonia;5942.00\")\n",
    "#a.join(b,\"cpf\")\n",
    "\n",
    "#del a, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data-generation/sample100.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-0e0a016b3eb2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;34m\"\"\"Loads toy data from file\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../data-generation/sample100.csv\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mtoLoad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data-generation/sample100.csv'"
     ]
    }
   ],
   "source": [
    "import os, random"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
